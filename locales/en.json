{
  "language": "English",
  "code": "en",
  "app": {
    "title": "Annotix",
    "subtitle": "Professional annotation tool",
    "branding": {
      "fablab": "TecMedHub",
      "university": "Universidad Austral de Chile - Puerto Montt Campus"
    }
  },
  "header": {
    "selectProject": "Select project...",
    "newProject": "New Project",
    "openProject": "Open Project",
    "manageProjects": "Manage Projects",
    "exportProject": "Export Complete Project",
    "exportConfig": "Export Configuration",
    "importConfig": "Import Configuration",
    "help": "Help"
  },
  "tools": {
    "title": "Tools",
    "bbox": "Box",
    "obb": "OBB",
    "mask": "Mask",
    "select": "Select",
    "pan": "Pan",
    "newInstance": "New Instance",
    "tooltips": {
      "bbox": "Bounding Box (B)",
      "obb": "Oriented Box (O)",
      "mask": "Mask (M)",
      "select": "Select (V)",
      "pan": "Pan (H)"
    }
  },
  "classes": {
    "title": "Active Classes",
    "manage": "Manage Classes",
    "add": "Add Class",
    "placeholder": "Class name",
    "empty": "Create a project first",
    "deleteConfirm": "There are annotations with this class. Delete anyway?",
    "exists": "A class with that name already exists",
    "enterName": "Enter a name for the class"
  },
  "images": {
    "title": "Load Image",
    "select": "Select images",
    "upload": "Select images",
    "noImages": "No images"
  },
  "actions": {
    "title": "Actions",
    "save": "Save",
    "undo": "Undo",
    "clear": "Clear",
    "delete": "Delete",
    "cancel": "Cancel",
    "create": "Create",
    "confirm": "Confirm",
    "close": "Close",
    "duplicate": "Duplicate",
    "rename": "Rename",
    "exportBackup": "Export Backup",
    "deleteConfirm": "Yes, delete",
    "clearConfirm": "Clear all annotations from this image?"
  },
  "shortcuts": {
    "title": "Shortcuts",
    "save": "Save",
    "undo": "Undo",
    "delete": "Delete",
    "navigation": "Navigation",
    "bbox": "Bbox",
    "mask": "Mask",
    "select": "Select",
    "pan": "Pan",
    "classes": "Class 1-9"
  },
  "canvas": {
    "zoomIn": "Zoom In",
    "zoomOut": "Zoom Out",
    "resetZoom": "Reset Zoom",
    "toggleLabels": "Show/Hide Labels",
    "toggleGrid": "Show/Hide Grid",
    "prevImage": "Previous Image (‚Üê)",
    "nextImage": "Next Image (‚Üí)"
  },
  "stats": {
    "title": "Statistics",
    "images": "Images",
    "annotated": "Annotated",
    "labels": "Labels",
    "classes": "Classes",
    "progress": "images annotated"
  },
  "gallery": {
    "title": "Gallery",
    "all": "All",
    "annotated": "Annotated",
    "unannotated": "Unannotated",
    "empty": "No images",
    "deleteConfirm": "Delete this image?"
  },
  "export": {
    "title": "Export Project",
    "project": {
      "title": "Export Project (.tix)",
      "description": "To continue working later or share with your team",
      "withImages": "Include images (complete project)",
      "button": "Export Project"
    },
    "training": {
      "title": "Export for Training",
      "description": "Dataset ready to train your model (always includes images)",
      "tabExport": "Export",
      "tabCode": "Generate Code",
      "selectFormat": "Select the format:",
      "button": "Export Dataset"
    },
    "code": {
      "framework": "Framework",
      "model": "Model",
      "device": "Device",
      "epochs": "Epochs",
      "batch": "Batch Size",
      "imgsz": "Image Size",
      "preview": "Preview",
      "copy": "Copy Code",
      "downloadPy": "Download .py",
      "downloadIpynb": "Download .ipynb",
      "labels": {
        "model": "Model",
        "device": "Device",
        "epochs": "Epochs",
        "batchSize": "Batch Size",
        "imageSize": "Image Size",
        "sequenceLength": "Sequence Length",
        "forecastHorizon": "Forecast Horizon",
        "hiddenSize": "Hidden Size",
        "advancedOptions": "Advanced Options",
        "training": "Training",
        "optimizer": "Optimizer",
        "learningRate": "Learning Rate",
        "patience": "Patience (Early Stop)",
        "validationSplit": "Validation Split (%)",
        "dataAugmentation": "Data Augmentation",
        "metricsAndPlots": "Metrics & Plots",
        "modelExport": "Model Export"
      },
      "modelSizes": {
        "nano": "Nano (fastest)",
        "small": "Small",
        "medium": "Medium",
        "large": "Large",
        "xlarge": "XLarge (most accurate)"
      },
      "devices": {
        "cpu": "üñ•Ô∏è CPU",
        "gpu": "üéÆ GPU (CUDA)",
        "mps": "üçé Apple Silicon (MPS)"
      },
      "optimizers": {
        "adam": "Adam (recommended for beginners)",
        "adamw": "AdamW (Adam with improved weight decay)",
        "sgd": "SGD (classic, requires more tuning)",
        "rmsprop": "RMSprop (good for recurrent networks)"
      },
      "augmentation": {
        "mosaic": "Mosaic (combines 4 images)",
        "mixup": "Mixup (blends transparencies)",
        "hsv": "HSV (color jitter)",
        "flip": "Flips (horizontal/vertical)",
        "rotate": "Rotation",
        "scale": "Scale/Crop"
      },
      "metrics": {
        "savePlots": "Save training plots",
        "saveMetricsCsv": "Export metrics to CSV",
        "saveConfMatrix": "Confusion matrix",
        "savePrCurves": "Precision-Recall curves",
        "savePredictions": "Visualize predictions"
      },
      "exportFormats": {
        "onnx": "ONNX (recommended)",
        "torchscript": "TorchScript",
        "tflite": "TensorFlow Lite",
        "openvino": "OpenVINO",
        "coreml": "CoreML",
        "tensorrt": "TensorRT"
      },
      "template": {
        "generatedBy": "Automatically generated by Annotix",
        "projectType": "Project type",
        "important": "IMPORTANT",
        "installDeps": "Install dependencies before running",
        "importantCLI": "IMPORTANT: YOLOv5 uses CLI, not Python API",
        "importantDetectron2": "IMPORTANT: Detectron2 is more advanced but complex",
        "importantClassification": "IMPORTANT: Classification with modern architectures",
        "importantSegmentation": "IMPORTANT: Semantic segmentation with modern architectures",
        "installation": "INSTALL DEPENDENCIES",
        "cloneYOLOv5": "Clone YOLOv5 repository (first time only)",
        "trainCLI": "TRAIN WITH CLI",
        "trainingScript": "Training Script",
        "registerCOCO": "Register your dataset in COCO format",
        "modelConfiguration": "MODEL CONFIGURATION",
        "approxEpochs": "Approx epochs",
        "model": "MODEL",
        "lossOptimizer": "LOSS AND OPTIMIZER",
        "training": "Training",
        "validation": "Validation",
        "metrics": "Metrics",
        "saveBestModel": "Save best model",
        "evaluatingModel": "Evaluating model",
        "validateBestModel": "Validate with best model",
        "printMetrics": "Print key metrics",
        "predictValidation": "Predict on validation images",
        "changeToValFolder": "Change to your validation folder",
        "saveImagesWithPredictions": "Save images with predictions",
        "minConfidence": "Minimum confidence",
        "dontSaveLabels": "Don't save labels",
        "dontCropDetections": "Don't crop detections",
        "exportingProduction": "Exporting model to production formats",
        "exportProduction": "EXPORT MODEL FOR PRODUCTION",
        "yolov5Completed": "YOLOv5 training completed",
        "yolonasCompleted": "YOLO-NAS training completed",
        "unetLoaded": "U-Net model loaded",
        "availableArchitectures": "Available architectures",
        "calculateIoU": "Calculate IoU",
        "bestModelSaved": "Best model saved",
        "bestAccuracy": "Best accuracy",
        "bestIoU": "Best IoU",
        "saveMetrics": "Save metrics",
        "plotResults": "Plot results",
        "plotsSaved": "Plots saved in",
        "loadDataset": "Load dataset (structure: train/class1, train/class2, ...)",
        "trainTransforms": "Training transforms",
        "valTransforms": "Validation transforms",
        "trainSamples": "Train samples",
        "valSamples": "Val samples",
        "classes": "Classes",
        "torchvisionModels": "TorchVision models",
        "options": "Options",
        "timmModels": "timm models (more models available)",
        "lossOptimizerTitle": "Loss and Optimizer",
        "customDataset": "Custom dataset",
        "initialLearningRate": "Initial learning rate",
        "finalLearningRate": "Final learning rate (as fraction of lr0)",
        "momentumSGD": "Momentum for SGD",
        "weightDecay": "Weight decay (L2 regularization)",
        "callbacks": "Callbacks and saving",
        "earlyStoppingPatience": "Early stopping patience",
        "saveCheckpoints": "Save checkpoints",
        "savePeriod": "Save every N epochs",
        "generatePlots": "Generate training plots",
        "minConfidenceMatrix": "Minimum confidence for confusion matrix",
        "cacheImages": "Cache images (uses more RAM)",
        "numWorkers": "Number of workers for DataLoader",
        "resultsFolder": "Results folder",
        "experimentName": "Experiment name",
        "overwriteExperiments": "Overwrite existing experiments",
        "validateDuringTraining": "Validate during training",
        "valPercentage": "Validation percentage if no val split exists",
        "verboseMode": "Verbose mode",
        "forVisualization": "For visualizations",
        "forExportMetrics": "To export metrics",
        "pretrainedModel": "Pretrained model",
        "hyperparameters": "Hyperparameters",
        "numClasses": "Number of classes",
        "registerDataset": "REGISTER DATASET",
        "installation": "INSTALL DEPENDENCIES",
        "executeCmds": "Run these commands in your terminal",
        "configuration": "TRAINING CONFIGURATION",
        "modelAndDevice": "Model and device",
        "basicHyperparams": "Basic hyperparameters",
        "dataAugmentation": "Data Augmentation",
        "loadPretrainedModel": "LOAD PRETRAINED MODEL",
        "trainModel": "TRAIN THE MODEL",
        "evaluateModel": "EVALUATE THE MODEL",
        "exportMetrics": "EXPORT METRICS TO CSV",
        "visualizePredictions": "VISUALIZE PREDICTIONS",
        "exportForProduction": "EXPORT MODEL FOR PRODUCTION",
        "dataset": "Dataset",
        "basics": "Basics",
        "optimization": "Optimization",
        "callbacks": "Callbacks and saving",
        "visualization": "Visualization and metrics",
        "performance": "Performance",
        "validation": "Validation",
        "modelLoaded": "Model loaded",
        "parameters": "Parameters",
        "trainingCompleted": "TRAINING COMPLETED",
        "evaluating": "Evaluating model...",
        "finalMetrics": "FINAL METRICS",
        "metricsSaved": "Metrics saved in",
        "predictionsSaved": "Predictions saved in",
        "exportingModel": "Exporting model to production formats...",
        "onnxExported": "ONNX exported",
        "torchscriptExported": "TorchScript exported",
        "tfliteExported": "TFLite exported",
        "openvinoExported": "OpenVINO exported",
        "coremlExported": "CoreML exported",
        "tensorrtExported": "TensorRT exported",
        "allDone": "All done!",
        "resultsIn": "Results in",
        "bestModel": "Best model",
        "yoloUsesCli": "YOLOv5 uses CLI, not Python API",
        "cloneRepo": "Clone YOLOv5 repository (first time only)",
        "trainWithCli": "TRAIN WITH CLI",
        "validate": "VALIDATE",
        "yoloTrainingCompleted": "YOLOv5 training completed!",
        "prepareTrainer": "Prepare trainer",
        "configureDataset": "Configure dataset",
        "loadModel": "Load model",
        "train": "Train",
        "trainingCompletedShort": "Training completed!",
        "registerDataset": "REGISTER DATASET",
        "modelConfig": "MODEL CONFIGURATION",
        "datasets": "Datasets",
        "pretrainedModel": "Pretrained model",
        "hyperparameters": "Hyperparameters",
        "numClasses": "Number of classes",
        "output": "Output",
        "evaluate": "EVALUATE",
        "advancedButComplex": "is more advanced but complex",
        "customDataset": "Custom dataset",
        "lossAndOptimizer": "LOSS AND OPTIMIZER",
        "trainingLoop": "TRAINING",
        "saveBestModel": "Best model saved (accuracy",
        "saveBestModelIoU": "Best model saved (IoU",
        "saveMetrics": "Save metrics",
        "plotResults": "Plot results",
        "bestAccuracy": "Best accuracy",
        "bestIoU": "Best IoU",
        "modernArchitectures": "with modern architectures",
        "semanticSegmentation": "Semantic segmentation with modern architectures",
        "forVisualization": "For visualizations",
        "forExportMetrics": "To export metrics",
        "trainingSamples": "Train samples",
        "valSamples": "Val samples",
        "classes": "Classes",
        "torchvisionModels": "TorchVision models",
        "timmModels": "timm models (more models available)",
        "lossOptimizerTitle": "Loss and Optimizer",
        "architecturesAvailable": "Available architectures",
        "trainSamples": "Training samples",
        "testSamples": "Test samples",
        "sequenceLength": "Sequence length",
        "numFeatures": "Number of features",
        "trainEpoch": "Training",
        "testEpoch": "Testing",
        "trainLoss": "Train Loss",
        "testLoss": "Test Loss",
        "trainAcc": "Train Acc",
        "testAcc": "Test Acc",
        "dataLoading": "DATA LOADING",
        "modelArchitecture": "MODEL ARCHITECTURE",
        "prepareData": "Prepare data",
        "trainTest": "TRAIN AND EVALUATE",
        "forecasting": "FORECASTING",
        "makePredictions": "Make predictions",
        "forecastHorizon": "Forecast horizon",
        "predictionsMade": "Predictions made",
        "trainingData": "Training data",
        "testingData": "Testing data",
        "scaler": "Data scaling",
        "sequences": "sequences",
        "timeSteps": "time steps",
        "features": "features"
      },
      "tooltips": {
        "framework": "Deep learning library to use. Adapts according to your project type.",
        "model": "Model size: Nano is fast but less accurate, XLarge is slow but more precise.",
        "device": "Where to train: CPU is slow but always works, GPU (CUDA) is very fast if you have NVIDIA.",
        "epochs": "How many times the model sees the entire dataset. More epochs = more learning but more time.",
        "batch": "How many images to process at once. Higher values use more memory but train faster.",
        "imgsz": "Resolution of images during training. Larger = more detail but slower.",
        "seqLength": "Number of time steps to use as input. E.g., use 50 past values to predict the future.",
        "forecastHorizon": "How many future steps to predict (forecasting only). E.g., predict next 10 values.",
        "hiddenSize": "Size of the neural network hidden layer (LSTM). Larger = more capacity but slower.",
        "optimizer": "Algorithm that adjusts model weights during training. Adam: balanced and popular. AdamW: Adam with improved weight decay. SGD: classic, slower but sometimes better final result. RMSprop: good for RNNs.",
        "lr": "How fast the model learns. High values = learns fast but can be unstable. 0.001 is a good starting point.",
        "patience": "How many epochs to wait without improvement before stopping. If model doesn't improve in 50 epochs, stops automatically.",
        "valSplit": "What percentage of your images to use for validation. 20% is standard: 80% trains, 20% validates.",
        "augmentationTitle": "Techniques to create variations of your images and prevent the model from memorizing. Helps generalize better.",
        "augMosaic": "Combines 4 random images into one. Very effective for improving small object detection.",
        "augMixup": "Mixes two images with transparency. Helps model be more robust against occlusions.",
        "augHsv": "Changes image colors (hue, saturation, brightness). Useful for different lighting conditions.",
        "augFlip": "Flips images horizontally or vertically. Doubles your data effortlessly.",
        "augRotate": "Rotates images slightly. Useful if your objects can appear at different angles.",
        "augScale": "Zooms in/out and randomly crops. Simulates objects at different distances.",
        "metricsTitle": "What information to save during training to analyze model performance.",
        "savePlots": "Saves loss and accuracy plots during training. Very useful to see if the model is learning.",
        "saveConfMatrix": "Table showing which classes are confused with each other. Ideal for understanding model errors.",
        "savePrCurves": "Graphs showing the balance between precision and recall. Important for evaluating detection quality.",
        "savePredictions": "Saves images with model predictions drawn on top. Perfect for visually seeing how well it works.",
        "saveMetricsCsv": "Exports all metrics to a CSV file for analysis in Excel or creating your own graphs.",
        "exportTitle": "Formats for deploying your trained model in production.",
        "exportOnnx": "ONNX: universal format, works with TensorFlow, PyTorch, and almost any library. Ideal for production.",
        "exportTorchscript": "TorchScript: PyTorch native format, very fast but only works with PyTorch.",
        "exportTflite": "TensorFlow Lite: for mobile and embedded devices (Android, iOS, Raspberry Pi).",
        "exportOpenvino": "OpenVINO: optimized for Intel CPUs. Very fast on Intel hardware.",
        "exportCoreml": "CoreML: for native iOS/macOS apps. Takes advantage of Apple chips.",
        "exportTensorrt": "TensorRT: maximum acceleration on NVIDIA GPUs. For high-performance production."
      },
      "codeCopied": "Code copied to clipboard",
      "copyError": "Error copying code",
      "pyDownloaded": "File .py downloaded",
      "ipynbDownloaded": "Notebook .ipynb downloaded",
      "trainingNotebook": "Training Notebook"
    },
    "formats": {
      "csvTimeSeries": {
        "name": "CSV for Time Series",
        "description": "Standard CSV format with timestamp, features and target columns"
      },
      "jsonTimeSeries": {
        "name": "Structured JSON",
        "description": "JSON format with metadata and structured time series"
      },
      "numpyTimeSeries": {
        "name": "NumPy Arrays (.npz)",
        "description": "Compressed NumPy arrays for efficient Python processing"
      },
      "csvAudio": {
        "name": "CSV for Audio",
        "description": "Audio metadata with file paths and labels"
      },
      "jsonAudio": {
        "name": "JSON for Audio",
        "description": "JSON format with audio configuration and annotations"
      },
      "csvVideo": {
        "name": "CSV for Video",
        "description": "Video metadata with timestamps and per-frame labels"
      },
      "jsonVideo": {
        "name": "JSON for Video",
        "description": "JSON format with video information and temporal annotations"
      },
      "csvText": {
        "name": "CSV for Text",
        "description": "CSV format with text and labels for NLP"
      },
      "jsonText": {
        "name": "JSON for Text",
        "description": "Structured JSON format for language processing tasks"
      },
      "yolo": {
        "name": "YOLO Detection",
        "description": "Bounding boxes in YOLO format (.txt) with data.yaml"
      },
      "yoloSeg": {
        "name": "YOLO Segmentation",
        "description": "Polygons in YOLO format (.txt) with data.yaml"
      },
      "yoloPose": {
        "name": "YOLO Pose",
        "description": "Keypoints in YOLO format (.txt) with skeleton configuration"
      },
      "coco": {
        "name": "COCO JSON",
        "description": "COCO format for Mask R-CNN, RetinaNet, etc."
      },
      "masksPng": {
        "name": "PNG Masks (U-Net)",
        "description": "PNG mask images for semantic segmentation"
      },
      "voc": {
        "name": "Pascal VOC XML",
        "description": "XML format with pixel coordinates"
      },
      "csv": {
        "name": "Simple CSV",
        "description": "CSV format for pandas processing"
      },
      "folders": {
        "name": "Folders by Class",
        "description": "Images organized in folders by class"
      },
      "json": {
        "name": "Complete JSON",
        "description": "JSON export with all annotations"
      }
    },
    "preparing": "Preparing export...",
    "success": "Dataset exported successfully",
    "downloadDataset": "Download Dataset"
  },
  "projectTypes": {
    "classification": "Simple Classification",
    "multiLabel": "Multi-Label Classification",
    "detection": "Object Detection",
    "segmentation": "Semantic Segmentation",
    "instanceSeg": "Instance Segmentation",
    "keypoints": "Keypoints",
    "obb": "Oriented Bounding Boxes (OBB)"
  },
  "project": {
    "new": "New Project",
    "name": "Project Name",
    "namePlaceholder": "My Annotix Project",
    "type": "Annotation Type",
    "typeSelectHelper": "Select the annotation type based on your training goal",
    "types": {
      "classification": {
        "name": "Simple Classification",
        "description": "Assign a single label to each complete image",
        "useCases": "Identify what the image contains (e.g., cat, dog, car)",
        "models": "ResNet, VGG, EfficientNet, MobileNet",
        "difficulty": "Beginner"
      },
      "multiLabel": {
        "name": "Multi-Label Classification",
        "description": "Assign multiple labels to each image",
        "useCases": "Image with several elements (e.g., park + dog + sky)",
        "models": "ResNet, VGG with multi-label output",
        "difficulty": "Beginner"
      },
      "detection": {
        "name": "Object Detection",
        "description": "Locate objects with rectangular boxes (bounding boxes)",
        "useCases": "Find and locate specific objects in the image",
        "models": "YOLO, SSD, Faster R-CNN, RetinaNet",
        "difficulty": "Intermediate"
      },
      "segmentation": {
        "name": "Semantic Segmentation",
        "description": "Classify each pixel of the image by class",
        "useCases": "Separate regions (e.g., road, sky, buildings)",
        "models": "U-Net, DeepLab, FCN",
        "difficulty": "Advanced"
      },
      "instanceSeg": {
        "name": "Instance Segmentation",
        "description": "Outline each individual object",
        "useCases": "Separate individual objects at pixel level",
        "models": "Mask R-CNN, YOLACT, YOLOv8-seg",
        "difficulty": "Advanced"
      },
      "keypoints": {
        "name": "Keypoints",
        "description": "Mark specific points on objects",
        "useCases": "Pose estimation, facial recognition, anatomy",
        "models": "OpenPose, HRNet, MediaPipe",
        "difficulty": "Intermediate"
      },
      "polygon": {
        "name": "Polygon Segmentation",
        "description": "Draw polygons point-by-point for precise segmentation",
        "useCases": "Precise object boundaries, geometric shapes, lighter than masks",
        "models": "YOLOv8-seg, Mask R-CNN, SOLO",
        "difficulty": "Intermediate"
      },
      "landmarks": {
        "name": "Landmark Points",
        "description": "Place independent points without connections",
        "useCases": "Object centers, reference points, counting, locations",
        "models": "Detection models, custom point detectors",
        "difficulty": "Beginner"
      },
      "obb": {
        "name": "Oriented Boxes (OBB)",
        "description": "Bounding boxes with free rotation",
        "useCases": "Angled text, aerial objects, satellites",
        "models": "Rotated-YOLO, RRPN",
        "difficulty": "Advanced"
      }
    },
    "initialClasses": "Initial Classes (optional)",
    "classesPlaceholder": "class1, class2, class3",
    "classesHelp": "Comma separated. You can add more later.",
    "imageDimensions": "Image Dimensions",
    "dimensionsAuto": "Automatic - Accept any size",
    "dimensionsFixed": "Fixed - All images will be resized",
    "targetSize": "Target size",
    "resizeStrategy": "Strategy",
    "enterName": "Enter a name for the project",
    "created": "Project \"{name}\" created",
    "updated": "Updated",
    "loaded": "Project \"{name}\" loaded",
    "deleted": "Project deleted",
    "duplicated": "Project \"{name}\" duplicated",
    "renamed": "Project renamed",
    "imported": "Project \"{name}\" imported",
    "exported": "Project exported",
    "configExported": "Configuration exported",
    "selectFirst": "Select a project first",
    "noProjects": "No projects available",
    "manageProjects": "Manage Projects",
    "renameProject": "Rename Project",
    "newName": "New name",
    "images": "images",
    "annotations": "annotations",
    "exportBackup": "Download .tix backup before deleting",
    "deleteWarning": {
      "title": "‚ö†Ô∏è WARNING: PERMANENT DELETION",
      "confirmTitle": "Confirm Deletion?",
      "projectName": "Project:",
      "message": "You are about to PERMANENTLY delete this project.",
      "permanent": "This action CANNOT be undone",
      "allData": "ALL images and annotations will be deleted",
      "noUndo": "There is no way to recover deleted data",
      "recommendation": "üí° Recommendation: Export the project in .tix format as a backup BEFORE deleting it"
    }
  },
  "notifications": {
    "imageSaved": "Image saved",
    "datasetDownloaded": "Dataset downloaded",
    "classesDownloaded": "classes.txt downloaded",
    "noClasses": "No classes to download",
    "noImages": "No images in project",
    "noAnnotations": "No annotations to download",
    "appStarted": "Application started",
    "error": {
      "createProject": "Error creating project",
      "loadProject": "Error loading project",
      "updateProject": "Error updating project",
      "deleteProject": "Error deleting project",
      "duplicateProject": "Error duplicating project",
      "renameProject": "Error renaming project",
      "loadProjects": "Error loading projects",
      "exportProject": "Error exporting project",
      "exportConfig": "Error exporting configuration",
      "importConfig": "Error importing configuration",
      "importProject": "Error importing project",
      "loadImage": "Error loading image",
      "saveImage": "Error saving image",
      "deleteImage": "Error deleting image",
      "loadImages": "Error loading images",
      "downloadDataset": "Error downloading dataset",
      "initApp": "Error starting application"
    }
  },
  "tour": {
    "welcome": "Welcome to <strong>Annotix</strong>. This tool allows you to annotate images for training machine learning models.",
    "project": "First, create a new project or select an existing one. Each project can be <strong>Bounding Box</strong> or <strong>Segmentation</strong> type.",
    "tools": "Here you'll find the annotation <strong>tools</strong>: Box for rectangles, Mask for paintable masks, Select for editing, and Pan to move the view.",
    "classes": "Define your annotation <strong>classes</strong>. Each class has a name and color. You can add, edit or delete classes.",
    "workspace": "The main <strong>workspace</strong>. Here you'll load your images and create annotations. Use the mouse to draw and wheel to zoom.",
    "management": "Management panel where you'll see project <strong>statistics</strong>, image <strong>gallery</strong> and can <strong>export</strong> your dataset in YOLO format.",
    "next": "Next ‚Üí",
    "prev": "‚Üê Previous",
    "done": "Done!",
    "skip": "Skip"
  },
  "imageInfo": {
    "noName": "No name",
    "dimensions": "Dimensions"
  },
  "polygon": {
    "toolName": "Polygon",
    "clickToAdd": "Click to add points. Double-click or press Enter to close.",
    "needMinPoints": "Need at least {min} points to create a polygon",
    "created": "Polygon created",
    "cancelled": "Drawing cancelled",
    "cannotDeletePoint": "Cannot delete point. Minimum {min} points required.",
    "pointDeleted": "Point deleted"
  },
  "landmarks": {
    "toolName": "Landmark",
    "placed": "Landmark \"{name}\" placed",
    "selectFirst": "Select a landmark first",
    "enterName": "Please enter a name",
    "renamed": "Landmark renamed",
    "renumbered": "Renumbered {count} landmarks",
    "renameLandmark": "Rename Landmark",
    "landmarkName": "Landmark Name:",
    "namePlaceholder": "e.g., Center, Top-Left, Entrance"
  },
  "skeleton": {
    "addKeypointClass": "Add Keypoint Class",
    "step1": "Step 1: Basic Information",
    "step2": "Step 2: Select Skeleton Preset",
    "className": "Class Name",
    "classNamePlaceholder": "e.g., Person, Hand, Face",
    "classColor": "Class Color",
    "selectPreset": "Select a skeleton preset for this class:",
    "presetInfo": "Each class can have its own skeleton. This allows you to annotate different types of objects in the same project.",
    "points": "points",
    "connections": "connections",
    "previous": "Previous",
    "next": "Next",
    "finish": "Finish",
    "presets": {
      "coco17": "COCO 17 Keypoints",
      "coco17Desc": "Full body human skeleton (COCO dataset)",
      "mediapipePose": "MediaPipe Pose 33",
      "mediapipePoseDesc": "Detailed full body pose",
      "mediapipeHand": "MediaPipe Hand 21",
      "mediapipeHandDesc": "Detailed hand joints",
      "openpose25": "OpenPose 25",
      "openpose25Desc": "OpenPose skeleton with hands",
      "facial68": "Facial Landmarks 68",
      "facial68Desc": "Detailed facial points",
      "facial5": "Facial 5 Points",
      "facial5Desc": "Basic facial points (eyes, nose, mouth)",
      "animalQuad": "Animal Quadruped",
      "animalQuadDesc": "Skeleton for 4-legged animals",
      "custom": "Custom",
      "customDesc": "Define your own skeleton"
    }
  },
  "preprocessing": {
    "title": "Preprocess Images",
    "detected": "Detected {count} non-square images",
    "description": "Images will be adjusted to a square size to optimize training. Choose the resizing strategy:",
    "targetSize": "Target size (pixels)",
    "recommended": "Recommended: {size}px",
    "strategy": "Resizing strategy",
    "strategies": {
      "resize": {
        "name": "Resize + Padding",
        "description": "Scales down the image and adds padding (optimizes space and memory)"
      },
      "padding": {
        "name": "Padding Only",
        "description": "Keeps original size and adds padding (better quality)"
      }
    },
    "options": {
      "apply": "Apply preprocessing",
      "skip": "Upload without preprocessing"
    },
    "progress": "Processing image {current} of {total}...",
    "complete": "{count} images preprocessed successfully",
    "preview": "Preview",
    "original": "Original",
    "processed": "Processed",
    "aspectRatio": "Original aspect ratio preserved",
    "paddingInfo": "Symmetric black padding will be added"
  },
  "classification": {
    "selectOne": "Select the correct label",
    "selectMultiple": "Select all labels that apply",
    "singleHint": "You can only select one label",
    "multiHint": "You can select multiple labels",
    "noLabels": "No labels assigned",
    "labeled": "Labeled"
  },
  "augmentation": {
    "title": "Data Augmentation",
    "batchButton": "Data Augmentation",
    "augmentImage": "Apply augmentation",
    "variationsCount": "Number of variations",
    "variationsCountHelp": "How many augmented images to create? (1-20)",
    "generationMode": "Generation mode",
    "modeManual": "Manual (fixed configuration)",
    "modeRandom": "Random (configurable ranges)",
    "modeManualHelp": "Apply the same configuration N times",
    "modeRandomHelp": "Generate N variations with random values within specified ranges",
    "geometricTransforms": "Geometric Transformations",
    "flipHorizontal": "Flip Horizontal",
    "flipVertical": "Flip Vertical",
    "rotation": "Rotation",
    "noRotation": "No rotation",
    "customRotation": "Custom rotation",
    "colorAdjustments": "Color Adjustments",
    "brightness": "Brightness",
    "contrast": "Contrast",
    "saturation": "Saturation",
    "randomOptions": "Random Options",
    "randomFlip": "Random flip (horizontal/vertical)",
    "randomRotation": "Random rotation",
    "randomColor": "Random color adjustments",
    "rotationRange": "Rotation range (degrees)",
    "brightnessRange": "Brightness range",
    "contrastRange": "Contrast range",
    "saturationRange": "Saturation range",
    "min": "Min",
    "max": "Max",
    "keepAnnotations": "Keep transformed annotations",
    "keepAnnotationsHelp": "Bounding boxes will be automatically transformed with the image",
    "maskProjectWarning": "Mask Project",
    "maskProjectWarningText": "Annotations will NOT be preserved. You'll need to manually paint masks on each augmented image.",
    "apply": "Apply",
    "processing": "Processing augmentation...",
    "generatingVariations": "Generating {count} variations...",
    "variationsSuccess": "{count} variations created successfully",
    "success": "Augmented image created successfully",
    "error": "Error applying augmentation",
    "batchProcessing": "Applying augmentation to {count} images...",
    "batchRandomProcessing": "Generating {variations} variations for {images} images ({total} total)...",
    "batchSuccess": "{count} augmented images created successfully",
    "batchRandomSuccess": "{count} random variations created successfully",
    "batchError": "Error applying batch augmentation"
  },
  "pwa": {
    "installButton": "Install App",
    "modal": {
      "title": "üöÄ Install Annotix as an app",
      "benefits": "Benefits of installing:",
      "benefit1": "‚úÖ Desktop shortcut access",
      "benefit2": "‚úÖ Works offline",
      "benefit3": "‚úÖ Faster and smoother",
      "benefit4": "‚úÖ No browser bar",
      "benefit5": "‚úÖ Your data always private",
      "benefit6": "‚úÖ Automatic updates",
      "cancelButton": "Not now",
      "installButtonModal": "üì• Install App"
    },
    "notifications": {
      "installed": "Annotix installed successfully!",
      "installFailed": "Error installing application",
      "updateAvailable": "Update available. Reload to update.",
      "offline": "Offline mode activated. App works without connection."
    }
  },
  "storage": {
    "used": "Storage used in IndexedDB"
  }
}
